{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "621bfb49",
   "metadata": {},
   "source": [
    "# Tweets_with_location Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28929c57",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5989132",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Tweets_with_location.csv'\n",
    "try:\n",
    "    tweets_df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"Error loading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dfeb1e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>TweetURL</th>\n",
       "      <th>UserURL</th>\n",
       "      <th>City</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gerald Butts</td>\n",
       "      <td>gmbutts</td>\n",
       "      <td>2022-01-24 22:24:00</td>\n",
       "      <td>I'm glad serious researchers are taking up thi...</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>https://twitter.com/gmbutts/status/14857402380...</td>\n",
       "      <td>https://twitter.com/gmbutts</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gerald Butts</td>\n",
       "      <td>gmbutts</td>\n",
       "      <td>2022-01-24 22:27:00</td>\n",
       "      <td>1. Partisan adhesion in Canada is weak and par...</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>https://twitter.com/gmbutts/status/14857409939...</td>\n",
       "      <td>https://twitter.com/gmbutts</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abigail Boyd</td>\n",
       "      <td>AbigailBoydMLC</td>\n",
       "      <td>2022-03-07 23:46:00</td>\n",
       "      <td>Minister Ayers, what are you doing to assist t...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>https://twitter.com/AbigailBoydMLC/status/1500...</td>\n",
       "      <td>https://twitter.com/AbigailBoydMLC</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warren Gunnels</td>\n",
       "      <td>GunnelsWarren</td>\n",
       "      <td>2022-02-22 23:49:00</td>\n",
       "      <td>I want cable news to cover the child poverty r...</td>\n",
       "      <td>5418</td>\n",
       "      <td>203000</td>\n",
       "      <td>https://twitter.com/GunnelsWarren/status/14962...</td>\n",
       "      <td>https://twitter.com/GunnelsWarren</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scalawag</td>\n",
       "      <td>scalawagmag</td>\n",
       "      <td>2022-03-21 21:45:00</td>\n",
       "      <td>\"If we don't adapt the internet to the reality...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>https://twitter.com/scalawagmag/status/1506024...</td>\n",
       "      <td>https://twitter.com/scalawagmag</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name        UserName                Time  \\\n",
       "0    Gerald Butts         gmbutts 2022-01-24 22:24:00   \n",
       "1    Gerald Butts         gmbutts 2022-01-24 22:27:00   \n",
       "2    Abigail Boyd  AbigailBoydMLC 2022-03-07 23:46:00   \n",
       "3  Warren Gunnels   GunnelsWarren 2022-02-22 23:49:00   \n",
       "4        Scalawag     scalawagmag 2022-03-21 21:45:00   \n",
       "\n",
       "                                                Text  Likes  Retweets  \\\n",
       "0  I'm glad serious researchers are taking up thi...     17        50   \n",
       "1  1. Partisan adhesion in Canada is weak and par...      2        31   \n",
       "2  Minister Ayers, what are you doing to assist t...      8        12   \n",
       "3  I want cable news to cover the child poverty r...   5418    203000   \n",
       "4  \"If we don't adapt the internet to the reality...      1         9   \n",
       "\n",
       "                                            TweetURL  \\\n",
       "0  https://twitter.com/gmbutts/status/14857402380...   \n",
       "1  https://twitter.com/gmbutts/status/14857409939...   \n",
       "2  https://twitter.com/AbigailBoydMLC/status/1500...   \n",
       "3  https://twitter.com/GunnelsWarren/status/14962...   \n",
       "4  https://twitter.com/scalawagmag/status/1506024...   \n",
       "\n",
       "                              UserURL City  Unnamed: 10  Unnamed: 11  \n",
       "0         https://twitter.com/gmbutts    0          NaN          NaN  \n",
       "1         https://twitter.com/gmbutts    0          NaN          NaN  \n",
       "2  https://twitter.com/AbigailBoydMLC    0          NaN          NaN  \n",
       "3   https://twitter.com/GunnelsWarren    0          NaN          NaN  \n",
       "4     https://twitter.com/scalawagmag    0          NaN          NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataframe for an initial assessment\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaabe96f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42796901",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Handle Missing Data:\n",
    "\n",
    "def handle_missing_data(df):\n",
    "    # Create a copy of the DataFrame to avoid warnings\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    # Drop rows with missing values in specified columns\n",
    "    columns_to_drop_na = ['Name', 'UserName', 'Time', 'Text', 'TweetURL', 'UserURL']\n",
    "    df_cleaned.dropna(subset=columns_to_drop_na, inplace=True)\n",
    "    \n",
    "    # Fill missing values in 'Likes' and 'Retweets' with 0\n",
    "    df_cleaned['Likes'].fillna(0, inplace=True)\n",
    "    df_cleaned['Retweets'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Drop the 'Country' column if not needed\n",
    "    if 'Country' in df_cleaned.columns:\n",
    "        df_cleaned.drop(columns=['Country'], inplace=True)\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b49df4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Data Type Conversion:\n",
    "\n",
    "def convert_data_types(df):\n",
    "    # Create a copy of the DataFrame to avoid warnings\n",
    "    df_converted = df.copy()\n",
    "    \n",
    "    # Convert 'Time' column to datetime\n",
    "    df_converted['Time'] = pd.to_datetime(df_converted['Time'])\n",
    "    \n",
    "    # Convert 'Likes' and 'Retweets' to integers\n",
    "    df_converted['Likes'] = df_converted['Likes'].astype(int)\n",
    "    df_converted['Retweets'] = df_converted['Retweets'].astype(int)\n",
    "    \n",
    "    return df_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247541da",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Text Cleaning:\n",
    "\n",
    "def clean_text(df):\n",
    "    # Create a copy of the DataFrame to avoid warnings\n",
    "    df_cleaned_text = df.copy()\n",
    "    \n",
    "    # Remove URLs from 'Text' column\n",
    "    df_cleaned_text['Text'] = df_cleaned_text['Text'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "    \n",
    "    # Add more text cleaning steps as needed, e.g., removing special characters, hashtags, mentions.\n",
    "    \n",
    "    return df_cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4f46caa",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after handling missing data:\n",
      "             Name        UserName                Time  \\\n",
      "0    Gerald Butts         gmbutts 2022-01-24 22:24:00   \n",
      "1    Gerald Butts         gmbutts 2022-01-24 22:27:00   \n",
      "2    Abigail Boyd  AbigailBoydMLC 2022-03-07 23:46:00   \n",
      "3  Warren Gunnels   GunnelsWarren 2022-02-22 23:49:00   \n",
      "4        Scalawag     scalawagmag 2022-03-21 21:45:00   \n",
      "\n",
      "                                                Text  Likes  Retweets  \\\n",
      "0  I'm glad serious researchers are taking up thi...     17        50   \n",
      "1  1. Partisan adhesion in Canada is weak and par...      2        31   \n",
      "2  Minister Ayers, what are you doing to assist t...      8        12   \n",
      "3  I want cable news to cover the child poverty r...   5418    203000   \n",
      "4  \"If we don't adapt the internet to the reality...      1         9   \n",
      "\n",
      "                                            TweetURL  \\\n",
      "0  https://twitter.com/gmbutts/status/14857402380...   \n",
      "1  https://twitter.com/gmbutts/status/14857409939...   \n",
      "2  https://twitter.com/AbigailBoydMLC/status/1500...   \n",
      "3  https://twitter.com/GunnelsWarren/status/14962...   \n",
      "4  https://twitter.com/scalawagmag/status/1506024...   \n",
      "\n",
      "                              UserURL City  Unnamed: 10  Unnamed: 11  \n",
      "0         https://twitter.com/gmbutts    0          NaN          NaN  \n",
      "1         https://twitter.com/gmbutts    0          NaN          NaN  \n",
      "2  https://twitter.com/AbigailBoydMLC    0          NaN          NaN  \n",
      "3   https://twitter.com/GunnelsWarren    0          NaN          NaN  \n",
      "4     https://twitter.com/scalawagmag    0          NaN          NaN  \n",
      "\n",
      "DataFrame after data type conversion:\n",
      "             Name        UserName                Time  \\\n",
      "0    Gerald Butts         gmbutts 2022-01-24 22:24:00   \n",
      "1    Gerald Butts         gmbutts 2022-01-24 22:27:00   \n",
      "2    Abigail Boyd  AbigailBoydMLC 2022-03-07 23:46:00   \n",
      "3  Warren Gunnels   GunnelsWarren 2022-02-22 23:49:00   \n",
      "4        Scalawag     scalawagmag 2022-03-21 21:45:00   \n",
      "\n",
      "                                                Text  Likes  Retweets  \\\n",
      "0  I'm glad serious researchers are taking up thi...     17        50   \n",
      "1  1. Partisan adhesion in Canada is weak and par...      2        31   \n",
      "2  Minister Ayers, what are you doing to assist t...      8        12   \n",
      "3  I want cable news to cover the child poverty r...   5418    203000   \n",
      "4  \"If we don't adapt the internet to the reality...      1         9   \n",
      "\n",
      "                                            TweetURL  \\\n",
      "0  https://twitter.com/gmbutts/status/14857402380...   \n",
      "1  https://twitter.com/gmbutts/status/14857409939...   \n",
      "2  https://twitter.com/AbigailBoydMLC/status/1500...   \n",
      "3  https://twitter.com/GunnelsWarren/status/14962...   \n",
      "4  https://twitter.com/scalawagmag/status/1506024...   \n",
      "\n",
      "                              UserURL City  Unnamed: 10  Unnamed: 11  \n",
      "0         https://twitter.com/gmbutts    0          NaN          NaN  \n",
      "1         https://twitter.com/gmbutts    0          NaN          NaN  \n",
      "2  https://twitter.com/AbigailBoydMLC    0          NaN          NaN  \n",
      "3   https://twitter.com/GunnelsWarren    0          NaN          NaN  \n",
      "4     https://twitter.com/scalawagmag    0          NaN          NaN  \n",
      "\n",
      "DataFrame after text cleaning:\n",
      "             Name        UserName                Time  \\\n",
      "0    Gerald Butts         gmbutts 2022-01-24 22:24:00   \n",
      "1    Gerald Butts         gmbutts 2022-01-24 22:27:00   \n",
      "2    Abigail Boyd  AbigailBoydMLC 2022-03-07 23:46:00   \n",
      "3  Warren Gunnels   GunnelsWarren 2022-02-22 23:49:00   \n",
      "4        Scalawag     scalawagmag 2022-03-21 21:45:00   \n",
      "\n",
      "                                                Text  Likes  Retweets  \\\n",
      "0  I'm glad serious researchers are taking up thi...     17        50   \n",
      "1  1. Partisan adhesion in Canada is weak and par...      2        31   \n",
      "2  Minister Ayers, what are you doing to assist t...      8        12   \n",
      "3  I want cable news to cover the child poverty r...   5418    203000   \n",
      "4  \"If we don't adapt the internet to the reality...      1         9   \n",
      "\n",
      "                                            TweetURL  \\\n",
      "0  https://twitter.com/gmbutts/status/14857402380...   \n",
      "1  https://twitter.com/gmbutts/status/14857409939...   \n",
      "2  https://twitter.com/AbigailBoydMLC/status/1500...   \n",
      "3  https://twitter.com/GunnelsWarren/status/14962...   \n",
      "4  https://twitter.com/scalawagmag/status/1506024...   \n",
      "\n",
      "                              UserURL City  Unnamed: 10  Unnamed: 11  \n",
      "0         https://twitter.com/gmbutts    0          NaN          NaN  \n",
      "1         https://twitter.com/gmbutts    0          NaN          NaN  \n",
      "2  https://twitter.com/AbigailBoydMLC    0          NaN          NaN  \n",
      "3   https://twitter.com/GunnelsWarren    0          NaN          NaN  \n",
      "4     https://twitter.com/scalawagmag    0          NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "# Clean the dataset\n",
    "tweets_df = handle_missing_data(tweets_df)\n",
    "print(\"\\nDataFrame after handling missing data:\")\n",
    "print(tweets_df.head())\n",
    "\n",
    "tweets_df = convert_data_types(tweets_df)\n",
    "print(\"\\nDataFrame after data type conversion:\")\n",
    "print(tweets_df.head())\n",
    "\n",
    "tweets_df = clean_text(tweets_df)\n",
    "print(\"\\nDataFrame after text cleaning:\")\n",
    "print(tweets_df.head())\n",
    "\n",
    "# Now, tweets_df contains the cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1224a321",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "046e8997",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def handle_missing_data(df):\n",
    "    # Handle missing data as discussed earlier\n",
    "    return df\n",
    "\n",
    "def convert_data_types(df):\n",
    "    # Convert data types as discussed earlier\n",
    "    return df\n",
    "\n",
    "def clean_text(df):\n",
    "    # Clean text data as discussed earlier\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ba91f4c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Outlier Analysis Function \n",
    "\n",
    "def outlier_analysis(df, column_name):\n",
    "    # Implement outlier analysis on a specific column (e.g., Likes, Retweets)\n",
    "    # Use statistical methods like Z-score or IQR to identify outliers\n",
    "    # Optionally, visualize the outliers\n",
    "    return df_with_outliers_removed  # Return a DataFrame with outliers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02113a6d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import community  # Import the community module for community detection\n",
    "\n",
    "# Function to create the Twitter interaction network\n",
    "def create_twitter_network(df):\n",
    "    # Create a network representation of Twitter interactions\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes (Twitter users)\n",
    "    for user in df['UserName']:\n",
    "        G.add_node(user)\n",
    "    \n",
    "    # Add edges (interactions - retweets)\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Retweets'] > 0:\n",
    "            G.add_edge(row['UserName'], row['Retweets'])\n",
    "    \n",
    "    return G  # Return the created network\n",
    "\n",
    "# Function to analyze the Twitter network\n",
    "def analyze_twitter_network(G):\n",
    "    # Analyze the Twitter network (e.g., calculate centrality measures, detect communities)\n",
    "    \n",
    "    # Example: Calculate degree centrality for each node\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    \n",
    "    # Example: Detect communities using Louvain method from the community module\n",
    "    partition = community.best_partition(G)\n",
    "    \n",
    "    return degree_centrality, partition  # Return the results of network analysis\n",
    "\n",
    "# Create the Twitter interaction network\n",
    "twitter_network = create_twitter_network(tweets_df)\n",
    "\n",
    "# Analyze the Twitter network\n",
    "degree_centrality, communities = analyze_twitter_network(twitter_network)\n",
    "\n",
    "# We can now use degree_centrality and communities for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a5e995a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Print degree centrality for each user\n",
    "#for user, centrality in degree_centrality.items():\n",
    "#    print(f\"User: {user}, Degree Centrality: {centrality}\")\n",
    "\n",
    "# Print communities\n",
    "#for user, community_id in communities.items():\n",
    "#    print(f\"User: {user}, Community ID: {community_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fbb1b7",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "692bc30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (3.7)\r\n",
      "Requirement already satisfied: click in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\r\n",
      "Requirement already satisfied: joblib in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.7.9)\r\n",
      "Requirement already satisfied: tqdm in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a303897d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm glad serious researchers are taking up thi...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>{'neg': 0.035, 'neu': 0.733, 'pos': 0.232, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. Partisan adhesion in Canada is weak and par...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>{'neg': 0.137, 'neu': 0.776, 'pos': 0.087, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Minister Ayers, what are you doing to assist t...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>{'neg': 0.027, 'neu': 0.853, 'pos': 0.12, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want cable news to cover the child poverty r...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>{'neg': 0.218, 'neu': 0.704, 'pos': 0.079, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"If we don't adapt the internet to the reality...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>{'neg': 0.049, 'neu': 0.907, 'pos': 0.044, 'co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Sentiment  \\\n",
       "0  I'm glad serious researchers are taking up thi...  Positive   \n",
       "1  1. Partisan adhesion in Canada is weak and par...  Negative   \n",
       "2  Minister Ayers, what are you doing to assist t...  Positive   \n",
       "3  I want cable news to cover the child poverty r...  Negative   \n",
       "4  \"If we don't adapt the internet to the reality...  Negative   \n",
       "\n",
       "                                    Sentiment_Scores  \n",
       "0  {'neg': 0.035, 'neu': 0.733, 'pos': 0.232, 'co...  \n",
       "1  {'neg': 0.137, 'neu': 0.776, 'pos': 0.087, 'co...  \n",
       "2  {'neg': 0.027, 'neu': 0.853, 'pos': 0.12, 'com...  \n",
       "3  {'neg': 0.218, 'neu': 0.704, 'pos': 0.079, 'co...  \n",
       "4  {'neg': 0.049, 'neu': 0.907, 'pos': 0.044, 'co...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment Analysis:\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Function for sentiment analysis\n",
    "def perform_sentiment_analysis(text):\n",
    "    # Initialize the sentiment analyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Get sentiment scores for the text\n",
    "    sentiment_scores = sia.polarity_scores(text)\n",
    "\n",
    "    # Determine sentiment based on compound score\n",
    "    if sentiment_scores['compound'] >= 0.05:\n",
    "        sentiment = 'Positive'\n",
    "    elif sentiment_scores['compound'] <= -0.05:\n",
    "        sentiment = 'Negative'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "\n",
    "    return sentiment, sentiment_scores\n",
    "\n",
    "# Apply sentiment analysis to the 'Text' column in tweets_df\n",
    "tweets_df['Sentiment'], tweets_df['Sentiment_Scores'] = zip(*tweets_df['Text'].apply(perform_sentiment_analysis))\n",
    "\n",
    "# Display the first few rows of the DataFrame with sentiment analysis results\n",
    "tweets_df[['Text', 'Sentiment', 'Sentiment_Scores']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65ce6f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.10.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Collecting FuzzyTM>=0.4.0 (from gensim)\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: pandas in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (from FuzzyTM>=0.4.0->gensim) (1.4.4)\n",
      "Collecting pyfume (from FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading pyFUME-0.2.25-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
      "Collecting simpful (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading simpful-2.11.0-py3-none-any.whl (32 kB)\n",
      "Collecting fst-pso (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/zahra/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Collecting miniful (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20430 sha256=4a6a107f7fe837ebc1d1864aba865c9811a2eaee856dba22a86036844434f7e2\n",
      "  Stored in directory: /Users/zahra/Library/Caches/pip/wheels/99/66/48/d7ce0c6927f6abf167bbcdee537affc7b92c03632f78028411\n",
      "  Building wheel for miniful (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3513 sha256=17bde3630c1763de44dc8efb7dc86f61acea7ecbd4acf3f7b1b3056508f3fe91\n",
      "  Stored in directory: /Users/zahra/Library/Caches/pip/wheels/d9/c7/71/db1d4646d963b34c530667501d3d6f34c0825eaffae2f0f2cb\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: simpful, miniful, fst-pso, pyfume, FuzzyTM\n",
      "Successfully installed FuzzyTM-2.0.5 fst-pso-1.8.1 miniful-0.0.6 pyfume-0.2.25 simpful-2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02f50e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.002*\"#climatechange\" + 0.002*\"#crypto\" + 0.002*\"#amd\" + 0.002*\"#ClimateChange\" + 0.001*\"?Ã\\x83Â\\x83Ã\\x82Â\\x83Ã\\x83Â\\x82Ã\\x82Â\\x83Ã\\x83Â\\x83Ã\\x82Â\\x82Ã\\x83Â\\x82Ã\\x82Â\\x83Ã\\x83Â\\x83Ã\\x82Â\\x83Ã\\x83Â\\x82Ã\\x82Â\\x82Ã\\x83Â\\x83Ã\\x82Â\\x82Ã\\x83Â\\x82Ã\\x82Â\\x99Ã\\x83Â\\x83Ã\\x82Â\\x83Ã\\x83Â\\x82Ã\\x82Â\\x83Ã\\x83Â\\x83Ã\\x82Â\\x82Ã\\x83Â\\x82Ã\\x82Â\\x83Ã\\x83Â\\x83Ã\\x82Â\\x83Ã\\x83Â\\x82Ã\\x82Â\\x82Ã\\x83Â\\x83Ã\\x82Â\\x82Ã\\x83Â\\x82Ã\\x82Â\"')\n",
      "(1, '0.016*\"to\" + 0.011*\"help\" + 0.011*\"by\" + 0.010*\"fair\" + 0.009*\"into\"')\n",
      "(2, '0.019*\"the\" + 0.017*\"of\" + 0.015*\"and\" + 0.014*\"Climate\" + 0.012*\"in\"')\n",
      "(3, '0.010*\"#ClimateChange\" + 0.008*\"#climatechange\" + 0.006*\"CLIMATE\" + 0.004*\"CHANGE\" + 0.003*\"THE\"')\n",
      "(4, '0.037*\"the\" + 0.034*\"to\" + 0.024*\"climate\" + 0.022*\"and\" + 0.020*\"of\"')\n",
      "[(0,\n",
      "  '0.002*\"#climatechange\" + 0.002*\"#crypto\" + 0.002*\"#amd\" + '\n",
      "  '0.002*\"#ClimateChange\" + '\n",
      "  '0.001*\"?Ã\\x83Â\\x83Ã\\x82Â\\x83Ã\\x83Â\\x82Ã\\x82Â\\x83Ã\\x83Â\\x83Ã\\x82Â\\x82Ã\\x83Â\\x82Ã\\x82Â\\x83Ã\\x83Â\\x83Ã\\x82Â\\x83Ã\\x83Â\\x82Ã\\x82Â\\x82Ã\\x83Â\\x83Ã\\x82Â\\x82Ã\\x83Â\\x82Ã\\x82Â\\x99Ã\\x83Â\\x83Ã\\x82Â\\x83Ã\\x83Â\\x82Ã\\x82Â\\x83Ã\\x83Â\\x83Ã\\x82Â\\x82Ã\\x83Â\\x82Ã\\x82Â\\x83Ã\\x83Â\\x83Ã\\x82Â\\x83Ã\\x83Â\\x82Ã\\x82Â\\x82Ã\\x83Â\\x83Ã\\x82Â\\x82Ã\\x83Â\\x82Ã\\x82Â\" '\n",
      "  '+ 0.001*\"Herschel\" + 0.001*\"#food\" + 0.001*\"#nature\" + 0.001*\"#jobs\" + '\n",
      "  '0.001*\"#travel\"'),\n",
      " (1,\n",
      "  '0.016*\"to\" + 0.011*\"help\" + 0.011*\"by\" + 0.010*\"fair\" + 0.009*\"into\" + '\n",
      "  '0.009*\"#LossAndDamage\" + 0.009*\"share\" + 0.009*\"its\" + 0.008*\"paying\" + '\n",
      "  '0.008*\"those\"'),\n",
      " (2,\n",
      "  '0.019*\"the\" + 0.017*\"of\" + 0.015*\"and\" + 0.014*\"Climate\" + 0.012*\"in\" + '\n",
      "  '0.009*\"on\" + 0.008*\"Change\" + 0.006*\"#climatechange\" + 0.006*\"The\" + '\n",
      "  '0.006*\"to\"'),\n",
      " (3,\n",
      "  '0.010*\"#ClimateChange\" + 0.008*\"#climatechange\" + 0.006*\"CLIMATE\" + '\n",
      "  '0.004*\"CHANGE\" + 0.003*\"THE\" + 0.003*\"#gloabalwarming\" + 0.003*\"#COP28UAE\" '\n",
      "  '+ 0.002*\"@COP28_UAE\" + 0.002*\"TO\" + 0.002*\"#TodayforTomorrow\"'),\n",
      " (4,\n",
      "  '0.037*\"the\" + 0.034*\"to\" + 0.024*\"climate\" + 0.022*\"and\" + 0.020*\"of\" + '\n",
      "  '0.016*\"a\" + 0.015*\"change\" + 0.015*\"is\" + 0.013*\"in\" + 0.009*\"for\"')]\n"
     ]
    }
   ],
   "source": [
    "# Topic Modeling:\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "# Function for topic modeling using LDA\n",
    "def perform_topic_modeling(texts, num_topics=5):\n",
    "    # Tokenize the text and create a dictionary and corpus\n",
    "    texts = [text.split() for text in texts]\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    # Create the LDA model\n",
    "    lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
    "\n",
    "    # Print the topics and their keywords\n",
    "    topics = lda_model.print_topics(num_words=5)\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "\n",
    "    return lda_model\n",
    "\n",
    "# Extract the 'Text' column from tweets_df\n",
    "tweet_texts = tweets_df['Text'].tolist()\n",
    "\n",
    "# Perform topic modeling with 5 topics\n",
    "lda_model = perform_topic_modeling(tweet_texts, num_topics=5)\n",
    "\n",
    "# Display the topics and their keywords\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd558f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Analysis:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
